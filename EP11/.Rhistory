# Nose bien para que se usan estos graficos, la explicacion esta en el script de ejemplo pero No la entiendo
# este es el grafico de que tiene solo 1 predictor
xs1 <- data.frame(Logit = log(fitted(modelo)/(1-fitted(modelo))),
Weight = entrenamiento[["Weight"]])
pxs1 <- ggscatter(data = xs1, x = "Logit", y = "Weight", conf.int = TRUE)
print(pxs1)
xm1 <- data.frame(Logit = log(fitted(modelo_adelante)/(1-fitted(modelo_adelante))),
Weight = entrenamiento[["Weight"]],
Navel.Girth = entrenamiento[["Navel.Girth"]],
Bicep.Girth = entrenamiento[["Bicep.Girth"]],
Bitrochanteric.diameter = entrenamiento[["Bitrochanteric.diameter"]]
)
xm1.l <- pivot_longer(xm1, -Logit, names_to = "Predictor", values_to = "Valor")
pxm1 <- ggscatter(data = xm1.l, x = "Logit", y = "Valor", conf.int = TRUE) +
geom_smooth(method = "loess") +
theme_bw() +
facet_wrap(~ Predictor, scales = "free_y")
print(pxm1)
#
# xm2 <- data.frame(Indice = 1:nrow(entrenamiento),
#                   Residuo.estandarizado = rstandard(modelo_adelante))
# pxm2 <- ggscatter(data = xm2, x = "Indice", y = "Residuo.estandarizado")
# print(pxm2)
# 2.2 Distribucion Normal de los residuos
cat("Prueba de Noramalidad para los residuos:\n")
print(shapiro.test(modelo_adelante$residuals)) # p-value > 0.05, siguen una distribucion Normal
# 2.3 Homocedasticidad de los residuos
cat("Prueba de homocedasticidad para los residuos:\n")
print(bptest(modelo_adelante)) # ojo que esta cambia respecto de RLM y RLS
# 2.4 Multicolinealidad
vifs <- vif(modelo_adelante)
cat("Verificar la multicolinealidad:\n")
cat("- VIFs: \n")
print(vifs)
cat("- Tolerancias:\n")
print(1/vifs)
cat("- VIF medio: ", mean(vifs), "\n")
# Con lo anterior tenemos que el modelo esta bien ajustado y es generalizable.
# Se evalúa el poder predictivo: usar matriz de confusion, primero se vera a maNo luego con las funciones de caret
# 1. sin paquetes caret/leaps
# modelo con los datos de entrenamiento
umbral = 0.5
probs.trm <- fitted(modelo_adelante)
preds.trm <- sapply(probs.trm,
function (p) ifelse (p >= umbral, "Sobrepeso", "No Sobrepeso"))
#preds.trm <- factor(preds.trm, levels = levels(entrenamiento[["EN"]]))
TP.trm <- sum(entrenamiento[["EN"]] == "Sobrepeso" & preds.trm == "Sobrepeso")
FP.trm <- sum(entrenamiento[["EN"]] == "No Sobrepeso" & preds.trm == "Sobrepeso")
TN.trm <- sum(entrenamiento[["EN"]] == "No Sobrepeso" & preds.trm == "No Sobrepeso")
FN.trm <- sum(entrenamiento[["EN"]] == "Sobrepeso" & preds.trm == "No Sobrepeso")
acc.trm <- (TP.trm + TN.trm) / (TP.trm + FP.trm + TN.trm + FN.trm)
sen.trm <- TP.trm / (TP.trm + FN.trm)
esp.trm <- TN.trm / (TN.trm + FP.trm)
# Ahora calculemos el poder predictivo del modelo adelante en los datos de prueba
probs.tem <- predict(modelo_adelante, prueba, type = "response")
preds.tem <- sapply(probs.tem,
function (p) ifelse (p >= umbral, "Sobrepeso", "No Sobrepeso"))
#preds.tem <- factor(preds.tem, levels = levels(prueba[["EN"]]))
TP.tem <- sum(prueba[["EN"]] == "Sobrepeso" & preds.tem == "Sobrepeso")
FP.tem <- sum(prueba[["EN"]] == "No Sobrepeso" & preds.tem == "Sobrepeso")
TN.tem <- sum(prueba[["EN"]] == "No Sobrepeso" & preds.tem == "No Sobrepeso")
FN.tem <- sum(prueba[["EN"]] == "Sobrepeso" & preds.tem == "No Sobrepeso")
acc.tem <- (TP.tem + TN.tem) / (TP.tem + FP.tem + TN.tem + FN.tem)
sen.tem <- TP.tem / (TP.tem + FN.tem)
esp.tem <- TN.tem / (TN.tem + FP.tem)
cat("\nRendimiento del modelo de RLogM:\n")
cat("    Exactitud entrenamiento:", sprintf("%.2f", acc.trm * 100), "\n")
cat("           Exactitud prueba:", sprintf("%.2f", acc.tem * 100), "\n")
cat(" Sensibilidad entrenamiento:", sprintf("%.2f", sen.trm * 100), "\n")
cat("        Sensibilidad prueba:", sprintf("%.2f", sen.tem * 100), "\n")
cat("Especificidad entrenamiento:", sprintf("%.2f", esp.trm * 100), "\n")
cat("       Especificidad prueba:", sprintf("%.2f", esp.tem * 100), "\n")
cat("\n")
library(caret)
cat("Evaluacion con conjunto de entrenamiento")
probs_e <- predict(modelo_adelante, entrenamiento, type = "response")
preds_e <- sapply(probs_e, function(p) ifelse(p >= 0.5, "Sobrepeso", "No Sobrepeso"))
preds_e <- factor(preds_e, levels = levels(muestra[["EN"]]))
roc_e <- roc(entrenamiento[["EN"]], probs_e)
plot(roc_e)
matriz_e <- confusionMatrix(preds_e, entrenamiento[["EN"]])
print(matriz_e)
cat("Evaluacion con conjunto de prueba")
probs_p <- predict(modelo_adelante, prueba, type = "response")
probs_p
preds_p <- sapply(probs_p, function(p) ifelse(p >= 0.5, "Sobrepeso", "No sobrepeso"))
preds_p <- factor(preds_p, levels = levels(muestra[["EN"]]))
roc_p <- roc(prueba[["EN"]], probs_p)
plot(roc_p)
matriz_p <- confusionMatrix(preds_p, prueba[["EN"]])
print(matriz_p)
knitr::opts_chunk$set(echo = TRUE)
#############
# Librerías #
#############
library(dplyr)
library(tidyverse)
library(ggpubr)
library(ggplot2)
library(tidyr)
library(reshape2)
library(pROC)
library(lmtest)
library(car)
datos <- read.csv2("EP09 Datos.csv", sep = ";")
# creacion columnas IMC y EN
datos$IMC <- datos$Weight / (datos$Height / 100) ^ 2
datos$EN <- ifelse(datos$IMC >= 25.0, "Sobrepeso", "No Sobrepeso")
datos$EN <- factor(datos$EN)
set.seed(821) # cambie la semilla para poder hacer bien el ejercicio, con la otra daba mal el modelo_adelante
# muestra 90 hombres
hombres <- datos[datos$Gender == 1, ]
hombre_Sobrepeso <- hombres[hombres$EN == "Sobrepeso",]
hombre_No_Sobrepeso <- hombres[hombres$EN == "No Sobrepeso",]
muestra_Sobrepeso <- hombre_Sobrepeso[sample(1:nrow(hombre_Sobrepeso), size = 45), ]
muestra_No_Sobrepeso <- hombre_No_Sobrepeso[sample(1:nrow(hombre_No_Sobrepeso), size = 45), ]
muestra <- rbind(muestra_No_Sobrepeso, muestra_Sobrepeso)
Sobrepeso30 <- muestra_Sobrepeso[1:30, ]
Sobrepeso15 <- muestra_Sobrepeso[31:45, ]
NoSobrepeso30 <- muestra_No_Sobrepeso[1:30, ]
NoSobrepeso15 <- muestra_No_Sobrepeso[31: 45, ]
entrenamiento <- rbind(Sobrepeso30, NoSobrepeso30)
prueba <- rbind(NoSobrepeso15, Sobrepeso15)
# 8 predictores ejercicio 9
predictores <- c( "Knees.diameter", "Bicep.Girth", "Chest.diameter", "Wrists.diameter", "Elbows.diameter", "Chest.depth", "Bitrochanteric.diameter", "Navel.Girth")
# Se selecciona el predictor peso para predecir la variable EN.
# Se construye el modelo de regresion logistica con el predictor seleccionado
entrenamiento$EN <- as.factor(entrenamiento$EN)
modelo <- glm(EN ~ Weight,  data = entrenamiento, family = binomial(link = "logit")) # ojo de usar factor
formula <- formula(paste(c(". ~ .", predictores), collapse = " + "))
# por lo que entiendo esto lo que hace es agregarle los predicotores al modelo que ya teniamos
modelo_completo <- update(modelo, formula)
summary(modelo_completo)
# Agregamos predicotores usando seleccion hacia adelante
modelo_adelante <- step(modelo, scope = list(lower = modelo, upper = modelo_completo), direction = "both")
summary(modelo_adelante)
# Se evalúa el modelo
# OJO que el ejercicio pedia evaluar los 2. Por lo mismo la multicolinealidad solo se verifica para los multiples, ver scritp de ejemplo
predictores_modelo_adelante <- names(coef(modelo_adelante))[-1]
datos_p <- entrenamiento[, c(predictores_modelo_adelante, "Weight")]
datos_p
resultados <- data.frame(respuesta_predicha = fitted(modelo_adelante))
resultados[["residuos_estandarizados"]] <- rstandard(modelo_adelante)
resultados[["residuos_estudiantizados"]] <- rstudent(modelo_adelante)
resultados[["distancia_Cook"]] <- cooks.distance(modelo_adelante)
resultados[["dfBeta"]] <- dfbeta(modelo_adelante)
resultados[["dffit"]] <- dffits(modelo_adelante)
resultados[["apalancamiento"]] <- hatvalues(modelo_adelante)
resultados[["covratio"]] <- covratio(modelo_adelante)
cat("Identificación de valores atípicos: \n")
# Buscamos las observciones con residuos estandarizados fuera del 95% esperado
sospechoso1 <- which(abs(resultados[["residuos_estandarizados"]]) > 1.96)
cat("- Residuos estandarizados fuera del 95% esperado: ", sospechoso1, "\n")
# Buscamos observaciones con distancia de Cook mayor a 1
sospechoso2 <- which(resultados[["distancia_cook"]] > 1)
cat("- Residuos con una distancia de Cook alta:", sospechoso2, "\n")
# Buscamos observaciones con apalancamiento mayor igual al doble del apalacamiento promedio
apal_medio <- (ncol(datos_p) + 1) / nrow(datos_p)
sospechoso3 <- which(resultados[["apalancamiento"]] > 2 * apal_medio)
cat("- Residuos con apalancamiento fuera del rango: ", sospechoso3, "\n")
sospechoso4 <- which(apply(resultados[["dfBeta"]] >= 1, 1, any))
names(sospechoso4) <- NULL
cat("- Residuos con DFBeta >= 1:", sospechoso4, "\n")
# Buscamos observaciones con razón de covarianza fuera de rango
inferior <- 1 - 3 * apal_medio
superior <- 1 + 3 * apal_medio
sospechoso5 <- which(resultados[["covratio"]] < inferior | resultados[["covratio"]] > superior)
cat("- Residuos con razón de covarianza fuera de rango: ", sospechoso5, "\n")
# Resumen de valores sospechosos
sospechosos <- c(sospechoso1, sospechoso2, sospechoso3, sospechoso4, sospechoso5)
sospechosos <- sort(unique(sospechosos))
cat("\nResumen de valores sospechosos: \n")
cat("Apalancamiento promedio: ", apal_medio, "\n")
cat("Intervalo razón de covarianza: [", inferior, "; ", superior, "]\n\n", sep = "")
print(round(resultados[sospechosos, c("distancia_Cook", "apalancamiento", "covratio")], 3))
# 2. Verificacion de condiciones a modo que el modelo sea generalizable
# 2.1 Independencia de los residuos
cat("Prueba de Durbin-Watson para autocorrelaciones ")
cat("entre errores:\n")
print(durbinWatsonTest(modelo_adelante)) # p-value > 0.05 concluye que son independientes, tener cuidado con el orden de los datos
# Nose bien para que se usan estos graficos, la explicacion esta en el script de ejemplo pero No la entiendo
# este es el grafico de que tiene solo 1 predictor
xs1 <- data.frame(Logit = log(fitted(modelo)/(1-fitted(modelo))),
Weight = entrenamiento[["Weight"]])
pxs1 <- ggscatter(data = xs1, x = "Logit", y = "Weight", conf.int = TRUE)
print(pxs1)
xm1 <- data.frame(Logit = log(fitted(modelo_adelante)/(1-fitted(modelo_adelante))),
Weight = entrenamiento[["Weight"]],
Navel.Girth = entrenamiento[["Navel.Girth"]],
Bicep.Girth = entrenamiento[["Bicep.Girth"]],
Bitrochanteric.diameter = entrenamiento[["Bitrochanteric.diameter"]]
)
xm1.l <- pivot_longer(xm1, -Logit, names_to = "Predictor", values_to = "Valor")
pxm1 <- ggscatter(data = xm1.l, x = "Logit", y = "Valor", conf.int = TRUE) +
geom_smooth(method = "loess") +
theme_bw() +
facet_wrap(~ Predictor, scales = "free_y")
print(pxm1)
#
# xm2 <- data.frame(Indice = 1:nrow(entrenamiento),
#                   Residuo.estandarizado = rstandard(modelo_adelante))
# pxm2 <- ggscatter(data = xm2, x = "Indice", y = "Residuo.estandarizado")
# print(pxm2)
# 2.2 Distribucion Normal de los residuos
cat("Prueba de Noramalidad para los residuos:\n")
print(shapiro.test(modelo_adelante$residuals)) # p-value > 0.05, siguen una distribucion Normal
# 2.3 Homocedasticidad de los residuos
cat("Prueba de homocedasticidad para los residuos:\n")
print(bptest(modelo_adelante)) # ojo que esta cambia respecto de RLM y RLS
# 2.4 Multicolinealidad
vifs <- vif(modelo_adelante)
cat("Verificar la multicolinealidad:\n")
cat("- VIFs: \n")
print(vifs)
cat("- Tolerancias:\n")
print(1/vifs)
cat("- VIF medio: ", mean(vifs), "\n")
# Con lo anterior tenemos que el modelo esta bien ajustado y es generalizable.
# Se evalúa el poder predictivo: usar matriz de confusion, primero se vera a maNo luego con las funciones de caret
# 1. sin paquetes caret/leaps
# modelo con los datos de entrenamiento
umbral = 0.5
probs.trm <- fitted(modelo_adelante)
preds.trm <- sapply(probs.trm,
function (p) ifelse (p >= umbral, "Sobrepeso", "No Sobrepeso"))
#preds.trm <- factor(preds.trm, levels = levels(entrenamiento[["EN"]]))
TP.trm <- sum(entrenamiento[["EN"]] == "Sobrepeso" & preds.trm == "Sobrepeso")
FP.trm <- sum(entrenamiento[["EN"]] == "No Sobrepeso" & preds.trm == "Sobrepeso")
TN.trm <- sum(entrenamiento[["EN"]] == "No Sobrepeso" & preds.trm == "No Sobrepeso")
FN.trm <- sum(entrenamiento[["EN"]] == "Sobrepeso" & preds.trm == "No Sobrepeso")
acc.trm <- (TP.trm + TN.trm) / (TP.trm + FP.trm + TN.trm + FN.trm)
sen.trm <- TP.trm / (TP.trm + FN.trm)
esp.trm <- TN.trm / (TN.trm + FP.trm)
# Ahora calculemos el poder predictivo del modelo adelante en los datos de prueba
probs.tem <- predict(modelo_adelante, prueba, type = "response")
preds.tem <- sapply(probs.tem,
function (p) ifelse (p >= umbral, "Sobrepeso", "No Sobrepeso"))
#preds.tem <- factor(preds.tem, levels = levels(prueba[["EN"]]))
TP.tem <- sum(prueba[["EN"]] == "Sobrepeso" & preds.tem == "Sobrepeso")
FP.tem <- sum(prueba[["EN"]] == "No Sobrepeso" & preds.tem == "Sobrepeso")
TN.tem <- sum(prueba[["EN"]] == "No Sobrepeso" & preds.tem == "No Sobrepeso")
FN.tem <- sum(prueba[["EN"]] == "Sobrepeso" & preds.tem == "No Sobrepeso")
acc.tem <- (TP.tem + TN.tem) / (TP.tem + FP.tem + TN.tem + FN.tem)
sen.tem <- TP.tem / (TP.tem + FN.tem)
esp.tem <- TN.tem / (TN.tem + FP.tem)
cat("\nRendimiento del modelo de RLogM:\n")
cat("    Exactitud entrenamiento:", sprintf("%.2f", acc.trm * 100), "\n")
cat("           Exactitud prueba:", sprintf("%.2f", acc.tem * 100), "\n")
cat(" Sensibilidad entrenamiento:", sprintf("%.2f", sen.trm * 100), "\n")
cat("        Sensibilidad prueba:", sprintf("%.2f", sen.tem * 100), "\n")
cat("Especificidad entrenamiento:", sprintf("%.2f", esp.trm * 100), "\n")
cat("       Especificidad prueba:", sprintf("%.2f", esp.tem * 100), "\n")
cat("\n")
library(caret)
cat("Evaluacion con conjunto de entrenamiento")
probs_e <- predict(modelo_adelante, entrenamiento, type = "response")
preds_e <- sapply(probs_e, function(p) ifelse(p >= 0.5, "Sobrepeso", "No Sobrepeso"))
preds_e <- factor(preds_e, levels = levels(muestra[["EN"]]))
roc_e <- roc(entrenamiento[["EN"]], probs_e)
plot(roc_e)
matriz_e <- confusionMatrix(preds_e, entrenamiento[["EN"]])
print(matriz_e)
cat("Evaluacion con conjunto de prueba")
probs_p <- predict(modelo_adelante, prueba, type = "response")
probs_p
preds_p <- sapply(probs_p, function(p) ifelse(p >= 0.5, "Sobrepeso", "No sobrepeso"))
preds_p <- factor(preds_p, levels = levels(muestra[["EN"]]))
roc_p <- roc(prueba[["EN"]], probs_p)
plot(roc_p)
matriz_p <- confusionMatrix(preds_p, prueba[["EN"]])
print(matriz_p)
knitr::opts_chunk$set(echo = TRUE)
#############
# Librerías #
#############
library(dplyr)
library(tidyverse)
library(ggpubr)
library(ggplot2)
library(tidyr)
library(reshape2)
library(pROC)
library(lmtest)
library(car)
datos <- read.csv2("EP09 Datos.csv", sep = ";")
# creacion columnas IMC y EN
datos$IMC <- datos$Weight / (datos$Height / 100) ^ 2
datos$EN <- ifelse(datos$IMC >= 25.0, "Sobrepeso", "No Sobrepeso")
datos$EN <- factor(datos$EN)
set.seed(8215) # cambie la semilla para poder hacer bien el ejercicio, con la otra daba mal el modelo_adelante
# muestra 90 hombres
hombres <- datos[datos$Gender == 1, ]
hombre_Sobrepeso <- hombres[hombres$EN == "Sobrepeso",]
hombre_No_Sobrepeso <- hombres[hombres$EN == "No Sobrepeso",]
muestra_Sobrepeso <- hombre_Sobrepeso[sample(1:nrow(hombre_Sobrepeso), size = 45), ]
muestra_No_Sobrepeso <- hombre_No_Sobrepeso[sample(1:nrow(hombre_No_Sobrepeso), size = 45), ]
muestra <- rbind(muestra_No_Sobrepeso, muestra_Sobrepeso)
Sobrepeso30 <- muestra_Sobrepeso[1:30, ]
Sobrepeso15 <- muestra_Sobrepeso[31:45, ]
NoSobrepeso30 <- muestra_No_Sobrepeso[1:30, ]
NoSobrepeso15 <- muestra_No_Sobrepeso[31: 45, ]
entrenamiento <- rbind(Sobrepeso30, NoSobrepeso30)
prueba <- rbind(NoSobrepeso15, Sobrepeso15)
# 8 predictores ejercicio 9
predictores <- c( "Knees.diameter", "Bicep.Girth", "Chest.diameter", "Wrists.diameter", "Elbows.diameter", "Chest.depth", "Bitrochanteric.diameter", "Navel.Girth")
# Se selecciona el predictor peso para predecir la variable EN.
# Se construye el modelo de regresion logistica con el predictor seleccionado
entrenamiento$EN <- as.factor(entrenamiento$EN)
modelo <- glm(EN ~ Weight,  data = entrenamiento, family = binomial(link = "logit")) # ojo de usar factor
formula <- formula(paste(c(". ~ .", predictores), collapse = " + "))
# por lo que entiendo esto lo que hace es agregarle los predicotores al modelo que ya teniamos
modelo_completo <- update(modelo, formula)
summary(modelo_completo)
# Agregamos predicotores usando seleccion hacia adelante
modelo_adelante <- step(modelo, scope = list(lower = modelo, upper = modelo_completo), direction = "both")
summary(modelo_adelante)
# Se evalúa el modelo
# OJO que el ejercicio pedia evaluar los 2. Por lo mismo la multicolinealidad solo se verifica para los multiples, ver scritp de ejemplo
predictores_modelo_adelante <- names(coef(modelo_adelante))[-1]
datos_p <- entrenamiento[, c(predictores_modelo_adelante, "Weight")]
datos_p
resultados <- data.frame(respuesta_predicha = fitted(modelo_adelante))
resultados[["residuos_estandarizados"]] <- rstandard(modelo_adelante)
resultados[["residuos_estudiantizados"]] <- rstudent(modelo_adelante)
resultados[["distancia_Cook"]] <- cooks.distance(modelo_adelante)
resultados[["dfBeta"]] <- dfbeta(modelo_adelante)
resultados[["dffit"]] <- dffits(modelo_adelante)
resultados[["apalancamiento"]] <- hatvalues(modelo_adelante)
resultados[["covratio"]] <- covratio(modelo_adelante)
cat("Identificación de valores atípicos: \n")
# Buscamos las observciones con residuos estandarizados fuera del 95% esperado
sospechoso1 <- which(abs(resultados[["residuos_estandarizados"]]) > 1.96)
cat("- Residuos estandarizados fuera del 95% esperado: ", sospechoso1, "\n")
# Buscamos observaciones con distancia de Cook mayor a 1
sospechoso2 <- which(resultados[["distancia_cook"]] > 1)
cat("- Residuos con una distancia de Cook alta:", sospechoso2, "\n")
# Buscamos observaciones con apalancamiento mayor igual al doble del apalacamiento promedio
apal_medio <- (ncol(datos_p) + 1) / nrow(datos_p)
sospechoso3 <- which(resultados[["apalancamiento"]] > 2 * apal_medio)
cat("- Residuos con apalancamiento fuera del rango: ", sospechoso3, "\n")
sospechoso4 <- which(apply(resultados[["dfBeta"]] >= 1, 1, any))
names(sospechoso4) <- NULL
cat("- Residuos con DFBeta >= 1:", sospechoso4, "\n")
# Buscamos observaciones con razón de covarianza fuera de rango
inferior <- 1 - 3 * apal_medio
superior <- 1 + 3 * apal_medio
sospechoso5 <- which(resultados[["covratio"]] < inferior | resultados[["covratio"]] > superior)
cat("- Residuos con razón de covarianza fuera de rango: ", sospechoso5, "\n")
# Resumen de valores sospechosos
sospechosos <- c(sospechoso1, sospechoso2, sospechoso3, sospechoso4, sospechoso5)
sospechosos <- sort(unique(sospechosos))
cat("\nResumen de valores sospechosos: \n")
cat("Apalancamiento promedio: ", apal_medio, "\n")
cat("Intervalo razón de covarianza: [", inferior, "; ", superior, "]\n\n", sep = "")
print(round(resultados[sospechosos, c("distancia_Cook", "apalancamiento", "covratio")], 3))
# 2. Verificacion de condiciones a modo que el modelo sea generalizable
# 2.1 Independencia de los residuos
cat("Prueba de Durbin-Watson para autocorrelaciones ")
cat("entre errores:\n")
print(durbinWatsonTest(modelo_adelante)) # p-value > 0.05 concluye que son independientes, tener cuidado con el orden de los datos
# Nose bien para que se usan estos graficos, la explicacion esta en el script de ejemplo pero No la entiendo
# este es el grafico de que tiene solo 1 predictor
xs1 <- data.frame(Logit = log(fitted(modelo)/(1-fitted(modelo))),
Weight = entrenamiento[["Weight"]])
pxs1 <- ggscatter(data = xs1, x = "Logit", y = "Weight", conf.int = TRUE)
print(pxs1)
xm1 <- data.frame(Logit = log(fitted(modelo_adelante)/(1-fitted(modelo_adelante))),
Weight = entrenamiento[["Weight"]],
Navel.Girth = entrenamiento[["Navel.Girth"]],
Bicep.Girth = entrenamiento[["Bicep.Girth"]],
Bitrochanteric.diameter = entrenamiento[["Bitrochanteric.diameter"]]
)
xm1.l <- pivot_longer(xm1, -Logit, names_to = "Predictor", values_to = "Valor")
pxm1 <- ggscatter(data = xm1.l, x = "Logit", y = "Valor", conf.int = TRUE) +
geom_smooth(method = "loess") +
theme_bw() +
facet_wrap(~ Predictor, scales = "free_y")
print(pxm1)
#
# xm2 <- data.frame(Indice = 1:nrow(entrenamiento),
#                   Residuo.estandarizado = rstandard(modelo_adelante))
# pxm2 <- ggscatter(data = xm2, x = "Indice", y = "Residuo.estandarizado")
# print(pxm2)
# 2.2 Distribucion Normal de los residuos
cat("Prueba de Noramalidad para los residuos:\n")
print(shapiro.test(modelo_adelante$residuals)) # p-value > 0.05, siguen una distribucion Normal
# 2.3 Homocedasticidad de los residuos
cat("Prueba de homocedasticidad para los residuos:\n")
print(bptest(modelo_adelante)) # ojo que esta cambia respecto de RLM y RLS
# 2.4 Multicolinealidad
vifs <- vif(modelo_adelante)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyverse)
library(ggpubr)
library(leaps)
library(caret)
library(pROC)
datos <- read.csv2("EP09 Datos.csv", sep = ";")
# Crear la variable IMC
datos$IMC <- datos$Weight / (datos$Height / 100)^2
# Sobrepeso: IMC >= 25.0
# No sobrepeso: IMC < 25.0
# Crear la variable dicotómica EN (estado nutricional)
datos$EN <- ifelse(datos$IMC >= 25.0, "Sobrepeso", "No Sobrepeso")
datos$EN <- factor(datos$EN)
head(datos)
set.seed(8215)
# Separo los datos con sobrepeso y sin sobrepeso
personas_sobrepeso = datos[datos$EN == "Sobrepeso",]
personas_no_sobrepeso = datos[datos$EN == "No Sobrepeso",]
# Obtengo una muestra de 50 de cada conjunto de datos que se separó
muestra_sobrepeso = personas_sobrepeso[sample(1:nrow(personas_sobrepeso), size = 50),]
muestra_no_sobrepeso = personas_no_sobrepeso[sample(1:nrow(personas_no_sobrepeso), size = 50),]
# Uno las dos muestras en una, asegurando que la mitad tiene sobrepeso y la otra mitad no sobrepeso
muestra_total = rbind(muestra_sobrepeso, muestra_no_sobrepeso)
# Se seleccionan 2 a 8 predictores
predictors <- muestra_total[, !(names(muestra_total)  %in% c("IMC", "EN"))]
predictores_busqueda <- regsubsets(Weight ~ ., data=predictors, nbest = 1, nvmax = 13)
plot(predictores_busqueda)
modelo_multiple <- train(Weight ~ Waist.Girth + Hip.Girth+  Thigh.Girth + Forearm.Girth +  Height, data = muestra_total, method = "lm",
trControl = trainControl(method = "boot", number = 100))
modelo_multiple
#modelo_multiple$finalModel$residuals :vvvvv
modelo_multiple_rfe <- rfe(IMC ~ . - Weight - Height - EN, data = muestra_total, sizes = 10:20, metric = "Rsquared",
rfeControl = rfeControl(functions = lmFuncs, method = "repeatedcv", number = 5, repeats = 5))
predictors(modelo_multiple_rfe)
muestra_logistica <- muestra_total %>% select(-c(IMC, Weight, Height))
modelo_logistico <- rfe(EN ~ ., data = muestra_logistica, sizes = 2:6, metric = "ROC",
rfeControl = rfeControl(functions = lrFuncs, method = "LOOCV"))
print(ggplot(modelo_logistico))
# no alcanzamos :c
library(car)
library(caret)
library(ggfortify)
library(ggpubr)
library(leaps)
library(lmtest)
library(pROC)
library(tidyverse)
# Fijamos la carpeta de trabajo
setwd("C:/Users/vicen/OneDrive/Escritorio/EPEI/EP11")
# Cargamos los datos y agregamos las variables IMC y EN
datos <- read.csv2("EP09 Datos.csv")
datos.ext <- datos %>% mutate(IMC = Weight / (Height / 100)**2) %>%
mutate(EN = ifelse(IMC < 25, "no sobrepeso", "sobrepeso"))
datos.ext[["Gender"]] <- factor(datos.ext[["Gender"]])
datos.ext[["EN"]] <- factor(datos.ext[["EN"]])
# Fijamos la semilla
set.seed(21111)
# Obtenemos la muestra
muestra.a <- datos.ext %>% filter(EN == "no sobrepeso") %>%
sample_n(50, replace = FALSE)
muestra.b <- datos.ext %>% filter(EN == "sobrepeso") %>%
sample_n(50, replace = FALSE)
# Vamos a desordenar la muestra para que no queden ordenados los grupos
muestra <- muestra.ordenada[sample(1:100), ]
# Borramos las versiones que ya no usaremos (liberamos memoria)
rm(muestra.a, muestra.b, muestra.ordenada)
cat("\n")
# Vamos a desordenar la muestra para que no queden ordenados los grupos
muestra <- muestra.ordenada[sample(1:100), ]
# Obtenemos la muestra
muestra.a <- datos.ext %>% filter(EN == "no sobrepeso") %>%
sample_n(50, replace = FALSE)
muestra.b <- datos.ext %>% filter(EN == "sobrepeso") %>%
sample_n(50, replace = FALSE)
muestra.ordenada <- rbind(muestra.a, muestra.b)
# Vamos a desordenar la muestra para que no queden ordenados los grupos
muestra <- muestra.ordenada[sample(1:100), ]
# Borramos las versiones que ya no usaremos (liberamos memoria)
rm(muestra.a, muestra.b, muestra.ordenada)
cat("\n")
cat("########################################################################\n")
cat("# Regresión lineal múltiple para la variable peso.\n")
cat("########################################################################\n")
cat("\n\n")
# Identificamos las columnas inútiles
IMC.i <- which(colnames(muestra) == "IMC")
EN.i <- which(colnames(muestra) == "EN")
# Seleccionamos predictores usando el método de todos los subconjuntos, teniendo
# cuidado de no considerar las variables inútiles.
sets <- regsubsets(Weight ~ ., data = muestra, nbest = 1, nvmax = 8,
force.out = c(IMC.i, EN.i) - 1, method = "exhaustive")
sets.summ <- summary(sets)
mejor.i <- which.min(sets.summ[["bic"]])
pred.noms <- names(which(sets.summ[["which"]][mejor.i, ])[-1])
plot(sets)
cat("Mejores predictores:\n")
print(pred.noms)
cat("\n")
# Como todas las variables del mejor subconjunto son numéricas (y no necesitan
# variables indicadora), los nombres coinciden con los existentes en los datos,
# por lo que podemos usarlos directamente para construir el modelo.
peso.fmla.tex <- paste("Weight", paste(pred.noms, collapse = "+"), sep ="~")
# Vamos a ajustar modelo usando bootstrapping con B remuestreas
B = 2999
peso.rlm.tr <- train(formula(peso.fmla.tex), data = muestra,
method = "lm",
trControl = trainControl(method = "boot", number = B))
# Seleccionamos predictores usando el método de todos los subconjuntos, teniendo
# cuidado de no considerar las variables inútiles.
sets <- regsubsets(Weight ~ ., data = muestra, nbest = 1, nvmax = 8,
force.out = c(IMC.i, EN.i) - 1, method = "exhaustive")
sets.summ <- summary(sets)
mejor.i <- which.min(sets.summ[["bic"]])
pred.noms <- names(which(sets.summ[["which"]][mejor.i, ])[-1])
plot(sets)
cat("Mejores predictores:\n")
print(pred.noms)
cat("\n")
sets
