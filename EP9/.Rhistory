knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyverse)
library(ggpubr)
library(caret)
datos <- read.csv2("EP09 Datos.csv", sep = ";")
set.seed(2122)
datos_m <- datos[datos$Gender == 0, ]
muestra_m = datos_m[sample(1:nrow(datos_m), size = 50),]
head(muestra_m)
num_columnas = 8
predictores_a <- sample(names(muestra_m), num_columnas)
print(predictores_a)
# Primero obtenemos el nombre de todos los predictores que no sean los 8 seleccionados
predictores_completo <- names(muestra_m)
resto_predictores <- setdiff(predictores_completo, predictores_a)
getCor <- function(predictores, data){
for (i in predictores) {
cor_test <- cor.test(data$Weight, data[[i]], method = "pearson")
cat("Coeficiente de correlación para", i, ":", cor_test$estimate, "\n")
}
}
getCor(resto_predictores, muestra_m)
# Paso 1: Justificar elección de la variable Waist.Girth
coef <- cor.test(muestra_m$Weight, muestra_m$Hip.Girth, method = "pearson")
cat("Coeficiente de correlación:", coef$estimate)
# Paso 2: realización del modelo lineal entre ambas variables
modelo <- lm(Weight ~ Hip.Girth, data = muestra_m)
summary(modelo)
# Paso 3: Gráfico del modelo
# Graficar el modelo
p <- ggscatter(muestra_m, x = "Hip.Girth", y = "Weight", color = "blue", fill = "orange" ,xlab = "grosor a la altura de la cintura en cm" , ylab = "Peso de la persona en kg",
xticks.by = 5)
p <- p + geom_smooth(method = lm, se = FALSE, colour = "red" )
print(p)
# A continuación se evaluará manualmente los predictores y se agregarán al modelo en caso de que corresponda
# Creamos una data frame con los datos de los 8 predictores aleatorios, la variable de respuesta y el predictor "Hip.Girth" seleccionado previamente
predictores_seleccionados <- select(muestra_m, one_of(predictores_a))
predictores_seleccionados$Weight <- muestra_m$Weight
predictores_seleccionados$Hip.Girth <- muestra_m$Hip.Girth
# El modelo incial en este caso ya considera la variable predictora Hip.Girth.
modelo_inicial <- modelo
#summary(modelo_inicial)
# Ajustamos el modelo completo.
modelo_completo <- lm(muestra_m$Weight ~ ., data = predictores_seleccionados)
#summary(modelo_completo)
# Evaluamos las variables para incorporar
print(add1(modelo_inicial, scope = modelo_completo))
# Seleccionamos la variable con menor AIC -> En este caso Chest.diameter
modelo_final  <- update(modelo_inicial, . ~ . + Chest.diameter)
# Analizamos cual es mejor, y así poder seguir agregando predictores
print(anova(modelo_inicial, modelo_final))
# Gracias al resultado anterior (p-value < 0.05) se puede concluir que el modelo al cual se le agregó un predictor es mejor que el anterior. Por lo tanto podemos seguir agregando predictores
# Evaluamos las variables para incorporar
print(add1(modelo_final, scope = modelo_completo))
# Seleccionamos la variable con menor AIC -> En este caso Bicep.Girth
modelo_final  <- update(modelo_final, . ~ . + Bicep.Girth)
print(anova(modelo_inicial, modelo_final))
# Gracias al resultado anterior (p-value < 0.05) se puede concluir que el modelo al cual se le agregó un predictor es mejor que el anterior. Por lo tanto podemos seguir agregando predictores
# Evaluamos las variables para incorporar
print(add1(modelo_final, scope = modelo_completo))
# Seleccionamos la variable con menor AIC -> En este caso Elbows.diameter
modelo_final  <- update(modelo_final, . ~ . + Elbows.diameter)
print(anova(modelo_inicial, modelo_final))
# Gracias al resultado anterior (p-value < 0.05) se puede concluir que el modelo al cual se le agregó un predictor es mejor que el anterior. Por lo tanto podemos seguir agregando predictores
# Evaluamos las variables para incorporar
print(add1(modelo_final, scope = modelo_completo))
# Seleccionamos la variable con menor AIC -> En este caso Navel.Girth
modelo_final  <- update(modelo_final, . ~ . + Navel.Girth)
print(anova(modelo_inicial, modelo_final))
# Gracias al resultado anterior (p-value < 0.05) se puede concluir que el modelo al cual se le agregó un predictor es mejor que el anterior. Por lo tanto podemos seguir agregando predictores
# Evaluamos las variables para incorporar
print(add1(modelo_final, scope = modelo_completo))
# Seleccionamos la variable con menor AIC -> En este caso Knees.diameter
modelo_final  <- update(modelo_final, . ~ . + Knees.diameter)
print(anova(modelo_inicial, modelo_final))
# Evaluación modelo de regresión multiple obtenida previamente
plot(modelo_final)
predictores <- names(coef(modelo_final))[-1]
datos_p <- muestra_m[, c(predictores, "Weight")]
resultados <- data.frame(respuesta_predicha = fitted(modelo_final))
resultados[["residuos_estandarizados"]] <- rstandard(modelo_final)
resultados[["residuos_estudiantizados"]] <- rstudent(modelo_final)
resultados[["distancia_Cook"]] <- cooks.distance(modelo_final)
resultados[["dfBeta"]] <- dfbeta(modelo_final)
resultados[["dffit"]] <- dffits(modelo_final)
resultados[["apalancamiento"]] <- hatvalues(modelo_final)
resultados[["covratio"]] <- covratio(modelo_final)
cat("Identificación de valores atípicos: \n")
# Buscamos las observciones con residuos estandarizados fuera del 95% esperado
sospechoso1 <- which(abs(resultados[["residuos_estandarizados"]]) > 1.96)
cat("- Residuos estandarizados fuera del 95% esperado: ", sospechoso1, "\n")
# Buscamos observaciones con distancia de Cook mayor a 1
sospechoso2 <- which(resultados[["distancia_cook"]] > 1)
cat("- Residuos con una distancia de Cook alta:", sospechoso2, "\n")
# Buscamos observaciones con apalancamiento mayor igual al doble del apalacamiento promedio
apal_medio <- (ncol(datos_p) + 1) / nrow(datos_p)
sospechoso3 <- which(resultados[["apalancamiento"]] > 2 * apal_medio)
cat("- Residuos con apalancamiento fuera del rango: ", sospechoso3, "\n")
sospechoso4 <- which(apply(resultados[["dfBeta"]] >= 1, 1, any))
names(sospechoso4) <- NULL
cat("- Residuos con DFBeta >= 1:", sospechoso4, "\n")
# Buscamos observaciones con razón de covarianza fuera de rango
inferior <- 1 - 3 * apal_medio
superior <- 1 + 3 * apal_medio
sospechoso5 <- which(resultados[["covratio"]] < inferior | resultados[["covratio"]] > superior)
cat("- Residuos con razón de covarianza fuera de rango: ", sospechoso5, "\n")
# Resumen de valores sospechosos
sospechosos <- c(sospechoso1, sospechoso2, sospechoso3, sospechoso4, sospechoso5)
sospechosos <- sort(unique(sospechosos))
cat("\nResumen de valores sospechosos: \n")
cat("Apalancamiento promedio: ", apal_medio, "\n")
cat("Intervalo razón de covarianza: [", inferior, "; ", superior, "]\n\n", sep = "")
print(round(resultados[sospechosos, c("distancia_Cook", "apalancamiento", "covratio")], 3))
# Como conjunto de datos se utilizará los obtenidos en el paso anterior. (datos_p)
n <- nrow(datos_p)
n_entrenamiento <- floor(0.7 * n)
muestra <- sample.int(n = n, size = n_entrenamiento, replace = FALSE)
entrenamiento <- datos_p[muestra, ]
prueba <- datos_p[-muestra, ]
modelo_vc <- train(Weight ~ Hip.Girth + Knees.diameter + Bicep.Girth + Chest.diameter + Elbows.diameter + Navel.Girth, data = entrenamiento, method = "lm",
trControl = trainControl(method = "cv", number = 5))
summary(modelo_vc)
predic_entrenamiento <- predict(modelo_vc, entrenamiento)
error_entrenamiento <- entrenamiento[["Weight"]] - predic_entrenamiento
mse_entrenamiento <- mean(error_entrenamiento ** 2)
cat("MSE para el conjunto de entrenamiento: ", mse_entrenamiento, "\n")
predic_prueba <- predict(modelo_vc, prueba)
error_prueba <- prueba[["Weight"]] - predic_prueba
mse_prueba <- mean(error_prueba ** 2)
cat("MSE para el conjunto de prueba: ", mse_prueba, "\n")
